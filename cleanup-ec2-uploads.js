const fs = require('fs');
const path = require('path');
const { PrismaClient } = require('@prisma/client');

const prisma = new PrismaClient();

// ì•ˆì „í•˜ê²Œ ë””ë ‰í† ë¦¬ ì‚­ì œ
function safeDeleteDirectory(dirPath) {
  if (!fs.existsSync(dirPath)) {
    console.log(`ğŸ“‚ Directory not found: ${dirPath}`);
    return false;
  }

  try {
    const files = fs.readdirSync(dirPath);
    
    for (const file of files) {
      const filePath = path.join(dirPath, file);
      const stat = fs.statSync(filePath);
      
      if (stat.isDirectory()) {
        safeDeleteDirectory(filePath);
      } else {
        fs.unlinkSync(filePath);
        console.log(`ğŸ—‘ï¸  Deleted file: ${filePath}`);
      }
    }
    
    fs.rmdirSync(dirPath);
    console.log(`ğŸ—‘ï¸  Deleted directory: ${dirPath}`);
    return true;
  } catch (error) {
    console.error(`âŒ Failed to delete ${dirPath}:`, error.message);
    return false;
  }
}

// ë°±ì—… ìƒì„±
function createBackup(sourceDir, backupDir) {
  if (!fs.existsSync(sourceDir)) {
    console.log(`ğŸ“‚ Source directory not found: ${sourceDir}`);
    return false;
  }

  try {
    if (!fs.existsSync(backupDir)) {
      fs.mkdirSync(backupDir, { recursive: true });
    }

    const files = fs.readdirSync(sourceDir);
    
    for (const file of files) {
      const sourcePath = path.join(sourceDir, file);
      const backupPath = path.join(backupDir, file);
      const stat = fs.statSync(sourcePath);
      
      if (stat.isDirectory()) {
        createBackup(sourcePath, backupPath);
      } else {
        fs.copyFileSync(sourcePath, backupPath);
        console.log(`ğŸ’¾ Backed up: ${sourcePath} â†’ ${backupPath}`);
      }
    }
    
    return true;
  } catch (error) {
    console.error(`âŒ Failed to create backup:`, error.message);
    return false;
  }
}

// S3 ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ í™•ì¸
async function verifyMigration() {
  console.log('ğŸ” Verifying S3 migration completion...');
  
  try {
    // S3 URLì´ ì•„ë‹Œ avatarUrl í™•ì¸
    const [users, characters, personas] = await Promise.all([
      prisma.user.count({
        where: {
          avatarUrl: {
            not: null,
            not: { startsWith: 'https://mingling-new.s3' }
          }
        }
      }),
      prisma.character.count({
        where: {
          avatarUrl: {
            not: null,
            not: { startsWith: 'https://mingling-new.s3' }
          }
        }
      }),
      prisma.persona.count({
        where: {
          avatarUrl: {
            not: null,
            not: { startsWith: 'https://mingling-new.s3' }
          }
        }
      })
    ]);

    const totalNonS3 = users + characters + personas;
    
    if (totalNonS3 > 0) {
      console.log(`âš ï¸  Warning: ${totalNonS3} records still have non-S3 URLs:`);
      console.log(`   - Users: ${users}`);
      console.log(`   - Characters: ${characters}`);
      console.log(`   - Personas: ${personas}`);
      return false;
    } else {
      console.log('âœ… All avatarUrl records are using S3 URLs');
      return true;
    }
  } catch (error) {
    console.error('âŒ Failed to verify migration:', error);
    return false;
  }
}

// ë©”ì¸ í´ë¦°ì—… í•¨ìˆ˜
async function main() {
  console.log('ğŸ§¹ Starting EC2 uploads cleanup...');
  
  const uploadPaths = [
    './uploads',
    './backend/uploads',
    '/home/ubuntu/uploads',
    '/home/ubuntu/mingling_new/uploads',
    '/home/ubuntu/mingling_new/backend/uploads'
  ];

  // 1. ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ í™•ì¸
  const migrationComplete = await verifyMigration();
  
  if (!migrationComplete) {
    console.log('âŒ Migration not complete. Aborting cleanup.');
    console.log('ğŸ’¡ Please run the migration script first: node migrate-images-to-s3.js');
    return;
  }

  // 2. ë°±ì—… ìƒì„± (ì„ íƒì‚¬í•­)
  const createBackupConfirm = process.argv.includes('--backup');
  
  if (createBackupConfirm) {
    console.log('ğŸ’¾ Creating backup before cleanup...');
    const backupDir = `./uploads-backup-${Date.now()}`;
    
    for (const uploadPath of uploadPaths) {
      if (fs.existsSync(uploadPath)) {
        const backupPath = path.join(backupDir, path.basename(uploadPath));
        createBackup(uploadPath, backupPath);
      }
    }
  }

  // 3. uploads ë””ë ‰í† ë¦¬ ì‚­ì œ
  let deletedCount = 0;
  
  for (const uploadPath of uploadPaths) {
    if (safeDeleteDirectory(uploadPath)) {
      deletedCount++;
    }
  }

  // 4. ê²°ê³¼ ë³´ê³ 
  console.log('\nğŸ“Š Cleanup Summary:');
  console.log(`âœ… Deleted ${deletedCount} upload directories`);
  console.log('ğŸ‰ EC2 cleanup completed successfully!');
  
  if (createBackupConfirm) {
    console.log(`ğŸ’¾ Backup created in: ./uploads-backup-${Date.now()}`);
  }

  await prisma.$disconnect();
}

// ë„ì›€ë§ ì¶œë ¥
function showHelp() {
  console.log(`
ğŸ§¹ EC2 Uploads Cleanup Script

Usage:
  node cleanup-ec2-uploads.js [options]

Options:
  --backup    Create backup before deletion
  --help      Show this help message

Examples:
  node cleanup-ec2-uploads.js                    # Clean without backup
  node cleanup-ec2-uploads.js --backup           # Clean with backup
  
âš ï¸  Warning: This script will permanently delete upload directories.
   Make sure S3 migration is complete before running!
`);
}

// ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
if (require.main === module) {
  if (process.argv.includes('--help')) {
    showHelp();
  } else {
    main();
  }
}

module.exports = { main, verifyMigration, createBackup, safeDeleteDirectory }; 